{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliang9/nlpfa23/blob/main/gpt_english.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnlAgPVw6hkI",
        "outputId": "b988795f-35c8-46bb-ef3b-eea0bb0c5e85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n",
        "import openai\n",
        "import csv\n",
        "import re"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBwT6rEP7qvP",
        "outputId": "45f5e8df-3acf-4ddc-a75d-a6a19bf7e5b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(input_string):\n",
        "    punc = '''‘’“”!()-[]{};:'\"\\,<>./?@#$%^&*_~！？……。…～「⋯⋯⋯，（）：」『』．'''\n",
        "    for ele in input_string:\n",
        "        if ele in punc:\n",
        "            input_string = input_string.replace(ele, \"\")\n",
        "    return input_string\n",
        "\n",
        "def read_csv(file_path):\n",
        "    setups = []\n",
        "    punchlines = []\n",
        "\n",
        "    # read csv file\n",
        "    with open(file_path, 'r', newline='', encoding='utf-8') as csvfile:\n",
        "        csv_reader = csv.reader(csvfile)\n",
        "\n",
        "        for row in csv_reader:\n",
        "            if len(row) >= 2:\n",
        "                punchline = re.sub(r'\\s+', ' ', row[0].replace('\\n', ' ').replace('\\t', ''))\n",
        "                punchlines.append(remove_punctuation(punchline))\n",
        "                setup = re.sub(r'\\s+', ' ', row[1].replace('\\n', ' ').replace('\\t', ''))\n",
        "                setups.append(remove_punctuation(setup))\n",
        "\n",
        "    return punchlines, setups"
      ],
      "metadata": {
        "id": "G7xBlWuKcABP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset_path = '/content/drive/MyDrive/NLPProject/reddit-explanations-wgpt.csv'\n",
        "# joke_setups, joke_punchlines = read_csv(dataset_path)\n",
        "# joke_punchlines = joke_punchlines[1:]\n",
        "# joke_setups = joke_setups[1:]\n",
        "# print(joke_setups[:10])\n",
        "# print(joke_punchlines[:10])\n",
        "\n",
        "joke_setups = [\"A guy named Bart walks into a bar. He immediately gets shot and dies. Who killed him?\"]\n",
        "joke_punchlines = [\"the bartender\"]"
      ],
      "metadata": {
        "id": "m1XeQL258p6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp_setups = ['A man who lived by the sea grew a cucumber so large he was able to turn it into his house. One day a bad storm flooded the area with seawater and damaged his home', '‌‌I p‌‌roposed t‌‌o m‌‌y e‌‌x-wife t‌‌oday', 'US President Donald Trump tested and was not infected by the corona virus. Experts from the robert koch institute are not surprised', 'My girlfriend is like the coronavirus', 'My favorite childhood memory was building sandcastles with my grandmother']\n",
        "exp_punchlines = ['Now hes in a pickle', 'She s‌‌aid n‌‌o, s‌‌he t‌‌hinks Im j‌‌ust a‌‌fter m‌‌y m‌‌oney', 'The virus has been shown to affect lungs, not assholes', 'I dont have the coronavirus', 'until my mom took the urn from me']\n",
        "exp = ['This is funny because it is a play on words. Being \"in a pickle\" could mean that the man is in a difficult situation or that he is literally in a pickle, after the cucumber house was soaked in seawater.', 'This joke is funny because we expect someone to propose to someone else because they are after the money of the person they are going to marry, not their own money. The joke suggests that the person gave their ex-wife some of their money, and they are proposing to their ex-wife in order to get that money back. This is ironic because it means that the person is proposing to someone they intentionally divorced in order to get back their own money, not their ex-wifes money.', 'This is funny because it is unexpected. \"Lungs\" refers to the body part that the coronavirus affects, but \"assholes\" refers to people who are irritating rather than the body part.', 'This is funny because it is unexpected. One might expect that the person has a girlfriend who has certain qualities similar to the coronavirus so it is surprising that the person doesnt have the coronavirus.', 'This joke is funny because it subverts our expectations and has a play on words. The joke setup begins with a seemingly wholesome memory, and we expect the person to have built sandcastles \"with\" their grandfather--that is, alongside their grandfather. However, by mentioning the urn, the punchline reveals that the persons grandfather was actually dead, and the person was building sandcastles with his ashes.']"
      ],
      "metadata": {
        "id": "3_m921N4Bu4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your OpenAI API key\n",
        "openai.api_key = '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'\n",
        "\n",
        "\n",
        "# # Define your joke setups and punchlines\n",
        "# joke_setups = [\"Why did the chicken cross the road?\", \"What do you call a fish with no eyes?\", \"Why don't scientists trust atoms?\"]\n",
        "# joke_punchlines = [\"To get to the other side.\", \"Fsh.\", \"Because they make up everything.\"]\n",
        "\n",
        "# # Combine setups and punchlines for training examples\n",
        "# training_examples_5shot = [f\"This is the joke:{setup} {punchline}. {exp}\" for setup, punchline, exp in zip(exp_setups, exp_punchlines, exp)]\n",
        "# training_examples_3shot = training_examples_5shot[:3]  # Use the first 3 examples for 3-shot learning\n",
        "# training_examples_0shot = []  # No training examples for 0-shot learning\n",
        "\n",
        "# # Perform 5-shot learning\n",
        "# response_5shot = openai.ChatCompletion.create(\n",
        "#     model=\"text-davinci-003\",\n",
        "#     messages=training_examples_5shot,\n",
        "#     max_tokens=150\n",
        "# )\n",
        "\n",
        "# # Perform 3-shot learning\n",
        "# response_3shot = openai.ChatCompletion.create(\n",
        "#     model=\"text-davinci-003\",\n",
        "#     messages=training_examples_3shot,\n",
        "#     max_tokens=150\n",
        "# )\n",
        "\n",
        "# # Perform 0-shot learning\n",
        "# response_0shot = openai.ChatCompletion.create(\n",
        "#     model=\"text-davinci-003\",\n",
        "#     prompt=\"Explain why this joke is funny:\\nSetup: Why did the bicycle fall over?\\nPunchline: Because it was two-tired.\",\n",
        "#     max_tokens=150\n",
        "# )\n",
        "\n",
        "\n",
        "def generate_explanation(setup, punchline, examples_setup, examples_punchline, examples_explanation, num_shots=5):\n",
        "    # Combine the provided examples with the current setup and punchline\n",
        "\n",
        "    # Use GPT-3.5 to generate an explanation\n",
        "    if num_shots > 0:\n",
        "        prompt = \"Here are examples of jokes and explanations of why they are funny: \\n\".join([f\"{s}\\n{p}\\n{e}\\n\" for s, p, e in zip(examples_setup, examples_punchline, examples_explanation)])\n",
        "        prompt += f\"Please write an explanation for why this joke is funny: \\n{setup}\\n{punchline}\\n\"\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-1106\",  # Choose the appropriate engine\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            max_tokens=1000,  # Adjust as needed\n",
        "            n=1,\n",
        "            stop=None,  # Use None for dynamic stopping\n",
        "            temperature=0.7,  # Adjust temperature for creativity\n",
        "            frequency_penalty=0.0,\n",
        "        )\n",
        "    else:\n",
        "        prompt = f\"Please write an explanation for why this joke is funny: \\n{setup}\\n{punchline}\\n\"\n",
        "        response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-1106\",  # Choose the appropriate engine\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=1000,  # Adjust as needed\n",
        "        stop=None,  # Use None for dynamic stopping\n",
        "        temperature=0.7,  # Adjust temperature for creativity\n",
        "        frequency_penalty=0.0,\n",
        "    )\n",
        "    explanation = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "    return setup, punchline, explanation\n",
        "\n",
        "# Example usage with 5-shot learning\n",
        "for s, p in zip(joke_setups, joke_punchlines):\n",
        "      if s not in exp_setups and p not in exp_punchlines:\n",
        "          explanation_5_shot = generate_explanation(s, p, exp_setups, exp_punchlines, exp, num_shots=5)\n",
        "          print(\"5-shot learning explanation:\", explanation_5_shot)\n",
        "\n",
        "          # Example usage with 3-shot learning\n",
        "          explanation_3_shot = generate_explanation(s, p, exp_setups, exp_punchlines, exp, num_shots=3)\n",
        "          print(\"3-shot learning explanation:\", explanation_3_shot)\n",
        "\n",
        "          # Example usage with 0-shot learning\n",
        "          explanation_0_shot = generate_explanation(s, p, [], [], [], num_shots=0)\n",
        "          print(\"0-shot learning explanation:\", explanation_0_shot)\n"
      ],
      "metadata": {
        "id": "m93PH0ff6sZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc8c0e62-d7e5-4cd4-86e3-1cc8a414ba48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5-shot learning explanation: ('A guy named Bart walks into a bar. He immediately gets shot and dies. Who killed him?', 'the bartender', 'This joke is funny because it plays on the double meaning of \"bar.\" When the joke sets up the scenario of Bart walking into a bar, the listener expects the punchline to involve the setting of a drinking establishment. However, the unexpected twist is that \"bar\" also refers to a place where legal cases are heard, so the bartender in this case is the one who killed Bart. This unexpected play on words creates the humor in the joke.')\n",
            "3-shot learning explanation: ('A guy named Bart walks into a bar. He immediately gets shot and dies. Who killed him?', 'the bartender', 'This joke is funny because it plays on the double meaning of the word \"shot.\" When we hear \"shot\" in the context of a bar, we think of an alcoholic beverage. However, the joke subverts our expectations by revealing that Bart was actually shot with a gun, and the punchline provides a clever twist by revealing that the bartender, who usually serves shots of alcohol, is the one who killed him. The unexpected turn of events and the play on words make this joke humorous.')\n",
            "0-shot learning explanation: ('A guy named Bart walks into a bar. He immediately gets shot and dies. Who killed him?', 'the bartender', 'This joke is funny because it plays on the double meaning of \"bar.\" When the joke sets up the scenario of a guy named Bart walking into a bar, the listener naturally assumes it\\'s a watering hole. However, the punchline reveals that \"bar\" can also refer to the counter where drinks are served, and in this case, it\\'s the bartender who \"killed\" Bart. The unexpected twist and wordplay make the joke humorous.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT4 Explanations"
      ],
      "metadata": {
        "id": "TNeiwKbPgxSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your OpenAI API key\n",
        "openai.api_key = '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'\n",
        "\n",
        "\n",
        "# # Define your joke setups and punchlines\n",
        "# joke_setups = [\"Why did the chicken cross the road?\", \"What do you call a fish with no eyes?\", \"Why don't scientists trust atoms?\"]\n",
        "# joke_punchlines = [\"To get to the other side.\", \"Fsh.\", \"Because they make up everything.\"]\n",
        "\n",
        "# # Combine setups and punchlines for training examples\n",
        "# training_examples_5shot = [f\"This is the joke:{setup} {punchline}. {exp}\" for setup, punchline, exp in zip(exp_setups, exp_punchlines, exp)]\n",
        "# training_examples_3shot = training_examples_5shot[:3]  # Use the first 3 examples for 3-shot learning\n",
        "# training_examples_0shot = []  # No training examples for 0-shot learning\n",
        "\n",
        "# # Perform 5-shot learning\n",
        "# response_5shot = openai.ChatCompletion.create(\n",
        "#     model=\"text-davinci-003\",\n",
        "#     messages=training_examples_5shot,\n",
        "#     max_tokens=150\n",
        "# )\n",
        "\n",
        "# # Perform 3-shot learning\n",
        "# response_3shot = openai.ChatCompletion.create(\n",
        "#     model=\"text-davinci-003\",\n",
        "#     messages=training_examples_3shot,\n",
        "#     max_tokens=150\n",
        "# )\n",
        "\n",
        "# # Perform 0-shot learning\n",
        "# response_0shot = openai.ChatCompletion.create(\n",
        "#     model=\"text-davinci-003\",\n",
        "#     prompt=\"Explain why this joke is funny:\\nSetup: Why did the bicycle fall over?\\nPunchline: Because it was two-tired.\",\n",
        "#     max_tokens=150\n",
        "# )\n",
        "\n",
        "\n",
        "def generate_explanation(setup, punchline, examples_setup, examples_punchline, examples_explanation, num_shots=5):\n",
        "    # Combine the provided examples with the current setup and punchline\n",
        "\n",
        "    # Use GPT-3.5 to generate an explanation\n",
        "    if num_shots > 0:\n",
        "        prompt = \"Here are examples of jokes and explanations of why they are funny: \\n\".join([f\"{s}\\n{p}\\n{e}\\n\" for s, p, e in zip(examples_setup, examples_punchline, examples_explanation)])\n",
        "        prompt += f\"Please write an explanation for why this joke is funny: \\n{setup}\\n{punchline}\\n\"\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",  # Choose the appropriate engine\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            max_tokens=1000,  # Adjust as needed\n",
        "            n=1,\n",
        "            stop=None,  # Use None for dynamic stopping\n",
        "            temperature=0.7,  # Adjust temperature for creativity\n",
        "            frequency_penalty=0.0,\n",
        "        )\n",
        "    else:\n",
        "        prompt = f\"Please write an explanation for why this joke is funny: \\n{setup}\\n{punchline}\\n\"\n",
        "        response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",  # Choose the appropriate engine\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=1000,  # Adjust as needed\n",
        "        stop=None,  # Use None for dynamic stopping\n",
        "        temperature=0.7,  # Adjust temperature for creativity\n",
        "        frequency_penalty=0.0,\n",
        "    )\n",
        "    explanation = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "    return setup, punchline, explanation\n",
        "\n",
        "# Example usage with 5-shot learning\n",
        "for s, p in zip(joke_setups, joke_punchlines):\n",
        "      if s not in exp_setups and p not in exp_punchlines:\n",
        "          explanation_5_shot = generate_explanation(s, p, exp_setups, exp_punchlines, exp, num_shots=5)\n",
        "          print(\"5-shot learning explanation:\", explanation_5_shot)\n",
        "\n",
        "          # Example usage with 3-shot learning\n",
        "          explanation_3_shot = generate_explanation(s, p, exp_setups, exp_punchlines, exp, num_shots=3)\n",
        "          print(\"3-shot learning explanation:\", explanation_3_shot)\n",
        "\n",
        "          # Example usage with 0-shot learning\n",
        "          explanation_0_shot = generate_explanation(s, p, [], [], [], num_shots=0)\n",
        "          print(\"0-shot learning explanation:\", explanation_0_shot)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhgbNE7wbjju",
        "outputId": "2bd9a603-a31b-4f49-fb00-d02310399bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5-shot learning explanation: ('A guy named Bart walks into a bar. He immediately gets shot and dies. Who killed him?', 'the bartender', 'This joke is funny due to its play on words and the unexpected twist. At first, it sounds like the start of a typical bar joke (a guy walks into a bar). The twist is that Bart gets shot and dies, which is unexpected and darkly humorous in itself. The punchline, \"the bartender,\" is a pun on the victim\\'s name, Bart, and the shooter\\'s occupation, which is a bartender. The unexpectedness and the pun make this joke funny.')\n",
            "3-shot learning explanation: ('A guy named Bart walks into a bar. He immediately gets shot and dies. Who killed him?', 'the bartender', 'This joke is funny due to its play on words and the defying of expectations. The name \"Bart\" is short for \"bartender\", and when we hear of a man named Bart walking into a bar, we would normally expect a scene or a conversation to unfold. However, the punchline takes us by surprise with the sudden and unexpected death of Bart. The humor of the punchline lies in the revelation of the killer - the \"bartender\". It\\'s wordplay because \"Bart\" is contained within \"bartender\", adding an ironic twist. It\\'s a dark humor joke which depends on the surprise and incongruity between what we expect to happen and what actually happens.')\n",
            "0-shot learning explanation: ('A guy named Bart walks into a bar. He immediately gets shot and dies. Who killed him?', 'the bartender', 'This joke plays on the expectation of the listener. The listener is expecting a typical \\'guy walks into a bar\\' joke, which usually involves a humorous or absurd situation or conversation happening within the bar. Instead, the joke abruptly ends with Bart being shot and killed. The humor lies in the unexpectedness and absurdity of the situation. Also, in the pun that it\\'s the \"bartender\" who killed \"Bart\", creating a play on words.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 shot GPT-4\n",
        "python ../eval_crossval.py model=gpt-4~shots=5~task=matching~split=*.json --task matching\n",
        "python ../eval_crossval.py model=gpt-4~shots=5~task=ranking~split=*.json --task ranking\n",
        "python ../eval_crossval.py model=gpt-4~shots=5~task=explanation~split=*.json --task explanation\n",
        "\n",
        "# 5 shot GPT-3.5\n",
        "python ../eval_crossval.py model=gpt-4~shots=5~task=matching~split=*.json --task matching\n",
        "python ../eval_crossval.py model=gpt-4~shots=5~task=ranking~split=*.json --task ranking\n",
        "python ../eval_crossval.py model=gpt-4~shots=5~task=explanation~split=*.json --task explanation\n",
        "\n",
        "# Zero shot GPT-4 with chain-of-thought\n",
        "python ../eval_crossval.py model=gpt-4~task=matching~split=*.json --task matching\n",
        "python ../eval_crossval.py model=gpt-4~task=ranking~split=*.json --task ranking\n",
        "python ../eval_crossval.py model=gpt-4~task=explanation~split=*.json --task explanation\n",
        "\n",
        "# Zero shot GPT-3.5 with chain-of-thought\n",
        "python ../eval_crossval.py model=gpt-4~task=matching~split=*.json --task matching\n",
        "python ../eval_crossval.py model=gpt-4~task=ranking~split=*.json --task ranking\n",
        "python ../eval_crossval.py model=gpt-4~task=explanation~split=*.json --task explanation"
      ],
      "metadata": {
        "id": "r8r8-7Us67wR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}